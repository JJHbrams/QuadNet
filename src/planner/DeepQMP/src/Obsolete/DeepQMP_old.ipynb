{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxD_rEmgk6BB"
   },
   "source": [
    "\n",
    "<h1>Import packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1605525450268,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "fJDFAe96av6X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    " \n",
    "import pandas as pd\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "import numpy as np\n",
    " \n",
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    " \n",
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvkDJcculCpg"
   },
   "source": [
    "<h1>Data organization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1743,
     "status": "ok",
     "timestamp": 1605525450934,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "wN5ZGmzl482V"
   },
   "outputs": [],
   "source": [
    "class GenDataset(Dataset):\n",
    " \n",
    "  def __init__(self, X, transform=None):\n",
    "      self.X = X.float()\n",
    "      self.data = X[:-1,:].float()\n",
    "      self.target = X[1:,:-1].float()\n",
    "      \n",
    "  def __getitem__(self, index):\n",
    "      x = self.data[index]\n",
    "      y = self.target[index]\n",
    "      return x, y\n",
    " \n",
    "  def __len__(self):\n",
    "      return len(self.data)\n",
    " \n",
    "  def seq_data_gen(self, seq_size, input_dim, output_dim):\n",
    "      Data = self.data.view(-1, seq_size, input_dim)\n",
    "      Target = self.target.view(-1, seq_size, output_dim)\n",
    "      data_seq = []\n",
    "      target_seq = []\n",
    "      for seq in range(seq_size):\n",
    "        data_seq.append(Data[:,seq,:].tolist())\n",
    "        target_seq.append(Target[:,seq,:].tolist())\n",
    "      data_seq = torch.tensor(data_seq)\n",
    "      target_seq = torch.tensor(target_seq)\n",
    "\n",
    "      self.data = (data_seq[:,:,:]).float()\n",
    "      self.target = (target_seq[:,:,:]).float() \n",
    "      return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 10485,
     "status": "ok",
     "timestamp": 1605525459690,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "gaJ8SP1e62ob",
    "outputId": "a2de92a2-9b08-444f-83e6-337f0d91d5a0"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data=pd.read_csv('../../data/csv/Quadruped_data_100.txt')\n",
    "data=data.drop(\"Num\",axis=1)\n",
    "Quad_data = torch.tensor(data.values)\n",
    "Quad_data = Quad_data[:-1,:]\n",
    "# Quad_data = torch.cat([Quad_data[:,:].view(-1,62), Quad_data[-1,:].view(-1,62)],dim=0)\n",
    "print(np.shape(Quad_data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10990,
     "status": "ok",
     "timestamp": 1605525460209,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "ftqRTFrbsHep"
   },
   "outputs": [],
   "source": [
    "# Data organizing\n",
    "NUM_val=5000\n",
    "input_dim = 61\n",
    "output_dim = 60\n",
    "\n",
    "tr_data = Quad_data[0:len(Quad_data)-NUM_val,:]\n",
    "val_data= Quad_data[len(Quad_data)-NUM_val:,:]\n",
    "\n",
    "# Generate input and target\n",
    "tr_data = torch.cat([tr_data[:,:].view(-1,input_dim), tr_data[-1,:].view(-1,input_dim)],dim=0)\n",
    "Tr_dataset = GenDataset(tr_data)\n",
    "Xtr=Tr_dataset.data\n",
    "Ytr=Tr_dataset.target\n",
    "\n",
    "val_data = torch.cat([val_data[:,:].view(-1,input_dim), val_data[-1,:].view(-1,input_dim)],dim=0)\n",
    "Val_dataset = GenDataset(val_data)\n",
    "Xval=Val_dataset.data\n",
    "Yval=Val_dataset.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33986,
     "status": "ok",
     "timestamp": 1605525483215,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "KuEO_eiE4nOw"
   },
   "outputs": [],
   "source": [
    "seq_size=50 #약 1초\n",
    "\n",
    "Tr_dataset.seq_data_gen(seq_size, input_dim, output_dim)\n",
    "Xtr_LSTM=Tr_dataset.data\n",
    "Ytr_LSTM=Tr_dataset.target\n",
    "\n",
    "Val_dataset.seq_data_gen(seq_size, input_dim, output_dim)\n",
    "Xval_LSTM=Val_dataset.data\n",
    "Yval_LSTM=Val_dataset.target\n",
    "\n",
    "print(\"Seqeuntial data generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33979,
     "status": "ok",
     "timestamp": 1605525483218,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "F5IfcJWROKR8",
    "outputId": "82da7315-da12-41a6-f6e4-e03b0b4a39eb"
   },
   "outputs": [],
   "source": [
    "# Upload data on GPU\n",
    "# Xtr=Xtr.to(device)\n",
    "# Xtr_LSTM=Xtr_LSTM.to(device)\n",
    "# Xval=Xval.to(device)\n",
    "# Xval_LSTM=Xval_LSTM.to(device)\n",
    "print('Xtr      : ',np.shape(Xtr))\n",
    "print('Xval     : ',np.shape(Xval))\n",
    "print('Xtr_LSTM : ',np.shape(Xtr_LSTM))\n",
    "print('Xval_LSTM: ',np.shape(Xval_LSTM))\n",
    "print('\\n')\n",
    "# Ytr=Ytr.to(device)\n",
    "# Ytr_LSTM=Ytr_LSTM.to(device)\n",
    "# Yval=Yval.to(device)\n",
    "# Yval_LSTM=Yval_LSTM.to(device)\n",
    "print('Ytr      : ',np.shape(Ytr))\n",
    "print('Yval     : ',np.shape(Yval))\n",
    "print('Ytr_LSTM : ',np.shape(Ytr_LSTM))\n",
    "print('Yval_LSTM: ',np.shape(Yval_LSTM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6MJCopKk8Xt"
   },
   "source": [
    "<h1>Network definition</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33966,
     "status": "ok",
     "timestamp": 1605525483218,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "BCAwrB6JSz_2"
   },
   "outputs": [],
   "source": [
    "class LSTMout(nn.Module):\n",
    "    def forward(self, X):\n",
    "        out_, _ = X\n",
    "        return out_\n",
    "\n",
    "class DeepQMP(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim): \n",
    "        super(DeepQMP, self).__init__() \n",
    "\n",
    "        # LSTM\n",
    "        self.lstm1 = nn.LSTM(input_dim,     hidden_dim[0], bias=True)   \n",
    "        self.lstm2 = nn.LSTM(hidden_dim[0], hidden_dim[1], bias=True) \n",
    "        dslayer1 = 64\n",
    "        dslayer2 = 64\n",
    "        self.myLSTM_mlp = nn.Sequential(\n",
    "          nn.Linear(hidden_dim[1],  dslayer1, bias=True),   nn.ReLU(),\n",
    "          nn.Linear(dslayer1,       dslayer2, bias=True),   nn.ReLU(),\n",
    "          nn.Linear(dslayer2,       output_dim, bias=True), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # MLP\n",
    "        nnlayer1 = 64\n",
    "        nnlayer2 = 64\n",
    "        self.myMLP = nn.Sequential(  \n",
    "          nn.Linear(input_dim,  nnlayer1, bias=True),   nn.ReLU(),\n",
    "          nn.Linear(nnlayer1,   nnlayer2, bias=True),   nn.ReLU(),\n",
    "          nn.Linear(nnlayer2,   output_dim, bias=True), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Weighted SUM\n",
    "        self.End = nn.Linear(in_features=output_dim*2, out_features=output_dim, bias=False)  \n",
    "      \n",
    "    # def forward(self, X):\n",
    "    def forward(self, X, HnC1, HnC2):\n",
    "        # X : data, HnC : Hiddne and Cell state\n",
    "        # LSTM\n",
    "        lstm_out1, _ = self.lstm1(X, HnC1)\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1, HnC2)\n",
    "        LSTMoutput = self.myLSTM_mlp(lstm_out2[-1])\n",
    "\n",
    "        # MLP\n",
    "        mlp_X = torch.cat([X[-1,:,0].view(-1,1), X[-1,:,1].view(-1,1)],dim=1)\n",
    "        for inx in range(input_dim-2):\n",
    "              mlp_X = torch.cat([mlp_X[:,0:inx+2], X[-1,:,inx+1].view(-1,1)],dim=1)\n",
    "\n",
    "        NNoutput = self.myMLP(mlp_X)\n",
    "\n",
    "        output_ = self.End(torch.cat([NNoutput.view(-1,output_dim), LSTMoutput.view(-1,output_dim)],dim=1))\n",
    "\n",
    "        return output_\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgM77Z9alOMx"
   },
   "source": [
    "<h1>Training sequence</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1605525741070,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "KZZA4QAc7ErJ"
   },
   "outputs": [],
   "source": [
    "# Network model\n",
    "# model = Net();\n",
    "hidden_dim=[64,64]\n",
    "model = DeepQMP(input_dim, hidden_dim, output_dim); # (input dimension=7, hidden1 state dimension=1, hidden2 state dimension=1, output dimension=8)\n",
    "# model = model.to(device)\n",
    "# if device == 'cuda':\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "#     cudnn.benchmark = True\n",
    "# loss and optimizer\n",
    "L1_loss = nn.L1Loss()\n",
    "L2_loss = nn.MSELoss()\n",
    "Huber_loss = nn.SmoothL1Loss()\n",
    "# optimizer = torch.optim.SGD(params=model.parameters(), lr=0.00001, momentum=0.9, weight_decay =0.0001)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.002)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience= 10,mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1605525689593,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "Qiaucdngr4zm"
   },
   "outputs": [],
   "source": [
    "def L1_regularization(model):\n",
    "    regularization_loss=0\n",
    "    for param in model.parameters():\n",
    "        regularization_loss += torch.sum(torch.abs(param))\n",
    "\n",
    "    return regularization_loss\n",
    " \n",
    "def L2_regularization(model):\n",
    "    regularization_loss=0\n",
    "    for param in model.parameters():\n",
    "        regularization_loss += param.norm(2)**2\n",
    "\n",
    "    return regularization_loss\n",
    "\n",
    "def Loss(hypo, X, Y):\n",
    "    # Clear display\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # alpha=0.01\n",
    "    # lambdaExp = 1\n",
    "    # lambdaRatio = 0.001\n",
    "    # lambdaIN = 0.0005;\n",
    "    # lambdaReg = 0.0001\n",
    "    alpha=0.0001\n",
    "    lambdaExp = 10\n",
    "    lambdaRatio = 0.001\n",
    "    lambdaIN = 1;\n",
    "    lambdaReg = 0.1\n",
    "\n",
    "    Lexp = L2_loss(input=hypo, target=Y)\n",
    "    Lin = L2_loss(input=hypo, target=X[:,:-1])\n",
    "    Lreg = L2_regularization(model)\n",
    "\n",
    "    return lambdaExp*Lexp + lambdaRatio*Lexp/(alpha+lambdaIN*Lin) + lambdaReg*Lreg\n",
    "    #   return Lexp\n",
    "#     return lambdaExp*Lexp + lambdaIN/(alpha+Lin) + lambdaReg*Lreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "1dYqBp3umUfl",
    "outputId": "7cda1b62-1579-4b38-c3f2-609269ecbce6"
   },
   "outputs": [],
   "source": [
    "# Learn\n",
    "model.train()\n",
    "epoch = 1000\n",
    "batch=1000\n",
    "batch_val=int(NUM_val/seq_size)\n",
    "THRESH=0.001\n",
    " \n",
    "hypothesis=[]\n",
    "prediction=[]\n",
    "\n",
    "train_loss=[]\n",
    "validation_loss=[]\n",
    "validation_step=[]\n",
    "\n",
    "trloss=0\n",
    "valloss=0\n",
    "\n",
    "SRT=0;END=SRT+batch;\n",
    "\n",
    "# Initialize H(X)\n",
    "hidden1 = torch.zeros(1, batch, hidden_dim[0], requires_grad=True)#.to(device)\n",
    "cell1 = torch.zeros(1, batch, hidden_dim[0], requires_grad=True)#.to(device)\n",
    "hidden2 = torch.zeros(1, batch, hidden_dim[1], requires_grad=True)#.to(device)\n",
    "cell2 = torch.zeros(1, batch, hidden_dim[1], requires_grad=True)#.to(device)\n",
    "\n",
    "for step in tqdm(range(epoch), position=0, leave=True):\n",
    "    # Sample among Training data\n",
    "    Xo = Xtr[seq_size-1::seq_size,:]#.to(device)\n",
    "    Yo = Ytr[seq_size-1::seq_size,:]#.to(device)\n",
    "    hypothesis = model(Xtr_LSTM[:,SRT:END,:], (hidden1, cell1), (hidden2, cell2))\n",
    "    trloss = Loss(hypothesis,Xo[SRT:END,:],Yo[SRT:END,:])\n",
    "    # Optimize\n",
    "    optimizer.zero_grad()\n",
    "    trloss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(trloss)\n",
    "    # Save train loss\n",
    "    train_loss.append(trloss.data)\n",
    "\n",
    "    # Validation\n",
    "    if step%10 == 0:\n",
    "        hidden_val1 = torch.zeros(1, batch_val, hidden_dim[0], requires_grad=False)#.to(device)\n",
    "        cell_val1 = torch.zeros(1, batch_val, hidden_dim[0], requires_grad=False)#.to(device)\n",
    "        hidden_val2 = torch.zeros(1, batch_val, hidden_dim[1], requires_grad=False)#.to(device)\n",
    "        cell_val2 = torch.zeros(1, batch_val, hidden_dim[1], requires_grad=False)#.to(device)\n",
    "        Xo = Xval[seq_size-1::seq_size,:]#.to(device)\n",
    "        Yo = Yval[seq_size-1::seq_size,:]#.to(device)\n",
    "        \n",
    "        hypothesis_ = model(Xval_LSTM, (hidden_val1, cell_val1), (hidden_val2, cell_val2))\n",
    "        valloss = Loss(hypothesis_,Xo[:,:],Yo)\n",
    "        validation_step.append(step)\n",
    "        validation_loss.append(valloss.data)\n",
    "  \n",
    "    # # Sequences    \n",
    "    num_sam = 100\n",
    "    plt.title(\"First \"+str(num_sam)+\" samples\")\n",
    "    plt.scatter(Xtr_LSTM[-1,SRT:SRT+num_sam,0].cpu(), Xtr_LSTM[-1,SRT:SRT+num_sam,1].cpu(),s=100.0, c='y', edgecolors='black', label='Start')\n",
    "    plt.scatter(Ytr_LSTM[-1,SRT:SRT+num_sam,0].cpu(), Ytr_LSTM[-1,SRT:SRT+num_sam,1].cpu(),s=60.0 , c='r', edgecolors='black', label='Goal')\n",
    "    plt.scatter(hypothesis[0:num_sam,0].cpu().detach().numpy(), hypothesis[0:num_sam,1].cpu().detach().numpy(),s=30.0 , c='c', alpha=0.8, label='Predict')\n",
    "    plt.legend(fontsize='x-large')\n",
    "    plt.savefig('./graph/Single_output.png',dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot and Save losses\n",
    "    plt.title(\"Train loss : \"+str(trloss.cpu().detach().numpy())+\"\\nValidation loss : \"+str(valloss.cpu().detach().numpy()))\n",
    "    loss1=plt.plot(train_loss, color='b', label='Train loss')\n",
    "    loss2=plt.plot(validation_step, validation_loss , color='r', label='Validation loss')\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./graph/LearningLoss.png',dpi=100)\n",
    "    plt.show()\n",
    "    # plt.clf()\n",
    "    \n",
    "     \n",
    "    # Save checkpoint\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': trloss},\n",
    "                \"./model/DeepQMP.tar\", pickle_protocol = 4)\n",
    "                \n",
    "    SRT=END\n",
    "    if SRT+batch>=len(Xtr[seq_size-1::seq_size]):\n",
    "        SRT=0\n",
    "    \n",
    "    END=SRT+batch;\n",
    "    if END>=len(Xtr[seq_size-1::seq_size]):\n",
    "        END=len(Xtr[seq_size-1::seq_size])\n",
    "        \n",
    "    if (trloss.data > 0.0) and (trloss.data < THRESH) and abs((valloss.detach().numpy() - trloss.detach().numpy()) < 1.0):\n",
    "        break;\n",
    " \n",
    "print(\"Final loss : \",trloss.data.item())\n",
    "t=time.localtime(time.time())\n",
    "plt.title(\"Train loss : \"+str(trloss.cpu().detach().numpy()))\n",
    "plt.plot(train_loss)\n",
    "plt.savefig('./graph/LearningLoss_'+str(t.tm_year)+str(t.tm_mon)+str(t.tm_mday)+str(t.tm_hour)+str(t.tm_min)+'.png',dpi=100)\n",
    "# plt.show()\n",
    " \n",
    "# Save model & parameters\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': trloss},\n",
    "            \"./model/DeepQMP\"+str(t.tm_year)+str(t.tm_mon)+str(t.tm_mday)+str(t.tm_hour)+str(t.tm_min)+\".tar\", pickle_protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = torch.zeros(1, 19900, hidden_dim[0], requires_grad=True)#.to(device)\n",
    "cell1 = torch.zeros(1, 19900, hidden_dim[0], requires_grad=True)#.to(device)\n",
    "hidden2 = torch.zeros(1, 19900, hidden_dim[1], requires_grad=True)#.to(device)\n",
    "cell2 = torch.zeros(1, 19900, hidden_dim[1], requires_grad=True)#.to(device)\n",
    "\n",
    "Xo = Xtr[seq_size-1::seq_size,:]#.to(device)\n",
    "Yo = Ytr[seq_size-1::seq_size,:]#.to(device)\n",
    "hypothesis = model(Xtr_LSTM, (hidden1, cell1), (hidden2, cell2))\n",
    "XYdist = torch.norm(hypothesis_[:,0:2]-Yo[:,0:2], 1)\n",
    "print(XYdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5,6,7,8,9]\n",
    "s=3\n",
    "print(a[s-1::s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTm2MYpSlfQi"
   },
   "source": [
    "<h1>Total test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60252,
     "status": "aborted",
     "timestamp": 1605525509546,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "GQk5KG3Oc_0o"
   },
   "outputs": [],
   "source": [
    "# Eval\n",
    "import copy\n",
    "model = DeepQMP(input_dim, hidden_dim, output_dim);\n",
    "# model = model.to(device)\n",
    "# if device == 'cuda':\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "#     cudnn.benchmark = True\n",
    "params = torch.load(\"./model/DeepQMP.tar\", map_location = \"cpu\")\n",
    "model.load_state_dict(params['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "err_x = []\n",
    "err_y = []\n",
    "err_yaw = []\n",
    "\n",
    "hidden_test1 = torch.zeros(1, 1, hidden_dim[0], requires_grad=False)#.to(device)\n",
    "cell_test1 = torch.zeros(1, 1, hidden_dim[0], requires_grad=False)#.to(device)\n",
    "hidden_test2 = torch.zeros(1, 1, hidden_dim[1], requires_grad=False)#.to(device)\n",
    "cell_test2 = torch.zeros(1, 1, hidden_dim[1], requires_grad=False)#.to(device)\n",
    " \n",
    "index = np.random.randint(len(Xval[seq_size-1::seq_size,:]))\n",
    "ts=int(round(time.time() * 1000))\n",
    "input = Xval_LSTM[:,index,:]\n",
    "\n",
    "Xo=Xval[seq_size-1::seq_size,:]\n",
    "hypo = model(input.view(seq_size,-1,input_dim),(hidden_test1, cell_test1),(hidden_test2, cell_test2))\n",
    "output=copy.deepcopy(Variable(hypo))\n",
    "output[:,0:2] = hypo[:,0:2]\n",
    " \n",
    "tf=int(round(time.time() * 1000))\n",
    "print(tf-ts,'ms')\n",
    " \n",
    "plt.title(\"Arbitrary sample - XY\")\n",
    "# plt.xlim(-22,22);plt.ylim(-22,22)\n",
    "plt.scatter(Xval_LSTM[:,index,0].cpu(), Xval_LSTM[:,index,1].cpu(),s=500.0, c='y', edgecolors='y', label='XY input')\n",
    "plt.scatter(Yval_LSTM[:,index,0].cpu(), Yval_LSTM[:,index,1].cpu(),s=200.0, c='r', edgecolors='r', label='XY expected')\n",
    "plt.scatter(output[:,0].item(), output[:,1].item(),s=100.0, c='b', edgecolors='black', linewidth=5, alpha=0.8 , label='XY predicted')\n",
    "plt.scatter(Xval_LSTM[0,index,0].cpu(), Xval_LSTM[0,index,1].cpu(),s=700.0, c='m', edgecolors='y', label='XY origin')\n",
    "plt.scatter(Xval_LSTM[-1,index,0].cpu(), Xval_LSTM[-1,index,1].cpu(),s=700.0, c='g', edgecolors='r', label='XY last')\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60246,
     "status": "aborted",
     "timestamp": 1605525509547,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "QGB2gzWIQR5N"
   },
   "outputs": [],
   "source": [
    "input = Xval[index,:]\n",
    " \n",
    "hidden_test1 = torch.zeros(1, 1, hidden_dim1).to(device)\n",
    "cell_test1 = torch.zeros(1, 1, hidden_dim1).to(device)\n",
    "hidden_test2 = torch.zeros(1, 1, hidden_dim2).to(device)\n",
    "cell_test2 = torch.zeros(1, 1, hidden_dim2).to(device)\n",
    "\n",
    "Xo=Xval\n",
    "hypo,(h1,c1),(h2,c2) = model(input.view(1,-1,input_dim),(hidden_test1, cell_test1),(hidden_test2, cell_test2))\n",
    "output=copy.deepcopy(Variable(hypo))\n",
    "output[:,0:2] = hypo[:,0:2]\n",
    " \n",
    "plt.title(\"Arbitrary sample - XY\")\n",
    "# plt.xlim(-22,22);plt.ylim(-22,22)\n",
    "plt.scatter(Xval[index,0].cpu(), Xval[index,1].cpu(),s=500.0, c='y', edgecolors='y', label='XY origin')\n",
    "plt.scatter(Yval[index,0].cpu(), Yval[index,1].cpu(),s=300.0, c='r', edgecolors='y', label='XY expected')\n",
    "plt.scatter(output[:,0].item(), output[:,1].item(),s=100.0, c='b', edgecolors='black', linewidth=5, alpha=0.8 , label='XY predicted')\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60240,
     "status": "aborted",
     "timestamp": 1605525509548,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "k5Z1L-VRmV2o"
   },
   "outputs": [],
   "source": [
    "batch_test = 1000\n",
    "# input = Xte.reshape(input_dim,-1,1)\n",
    "# input = Xte.reshape(3,-1,1)\n",
    "input = Xte_LSTM\n",
    "# input = Xte_ori\n",
    "hidden_test1 = torch.zeros(1, NUM_val, hidden_dim1)#.to(device)\n",
    "cell_test1 = torch.zeros(1, NUM_val, hidden_dim1)#.to(device)\n",
    "hidden_test2 = torch.zeros(1, NUM_val, hidden_dim2)#.to(device)\n",
    "cell_test2 = torch.zeros(1, NUM_val, hidden_dim2)#.to(device)\n",
    "hypo,(h1,c1),(h2,c2)  = model(input,(hidden_test1, cell_test1),(hidden_test2, cell_test2))\n",
    "output=copy.deepcopy(Variable(hypo))\n",
    "output[:,0:2] = hypo[:,0:2]/scaler + Xte_ori[:,0:2].to(device)\n",
    "output[:,2] = hypo[:,2] + Xte_ori[:,2].to(device)\n",
    "\n",
    "error_input = np.sqrt((np.square(Xte_ori[:,0:-2].cpu().numpy() - output.detach().cpu().numpy())).mean())\n",
    "error = (output-Yte_ori).cpu().detach().numpy()\n",
    "for i in range(len(error)):\n",
    "        if abs(error[i,2]) > 180:\n",
    "          error[i,2] = np.sign(error[i,2])*(360-abs(error[i,2]));\n",
    "error_target = np.sqrt(np.square(error).mean())\n",
    "\n",
    "Pred = output.cpu().detach().numpy()\n",
    " \n",
    "num_sam = 100\n",
    "plt.title(str(num_sam)+ \" samples. vs. Input - XY\")\n",
    "plt.scatter(Xte_LSTM_ori[0,0:num_sam,0].cpu(), Xte_LSTM_ori[1,0:num_sam,0].cpu(),s=50.0, c='y', edgecolors='black')\n",
    "plt.scatter(Pred[0:num_sam,0], Pred[0:num_sam,1],s=50.0 , c='c', edgecolors='black', alpha=0.8)\n",
    "plt.show()\n",
    "plt.title(str(num_sam)+ \" samples. vs. Target - XY\")\n",
    "plt.scatter(Yte_LSTM_ori[0,0:num_sam,0].cpu(), Yte_LSTM_ori[1,0:num_sam,0].cpu(),s=50.0 , c='r', edgecolors='black')\n",
    "plt.scatter(Pred[0:num_sam,0], Pred[0:num_sam,1],s=50.0 , c='c', edgecolors='black', alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.title(str(num_sam)+ \" samples. vs. Input - Yaw\")\n",
    "plt.plot(Xte_LSTM_ori[2,0:num_sam,0].cpu(),'.', c='y')\n",
    "plt.plot(Pred[0:num_sam,2],'.', c='c', alpha=0.8)\n",
    "plt.show()\n",
    "plt.title(str(num_sam)+ \" samples. vs. Target - Yaw\")\n",
    "plt.plot(Yte_LSTM_ori[2,0:num_sam,0].cpu(),'.', c='r')\n",
    "plt.plot(Pred[0:num_sam,2],'.', c='c', alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.title(str(num_sam)+ \" samples. vs. Input - dx\")\n",
    "Xte_ori=Xte_ori.cpu()\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,0]-Xte_ori[0:num_sam,0].numpy()),np.min(error[0:num_sam,0])),max(np.max(Pred[0:num_sam,0]-Xte_ori[0:num_sam,0].numpy()),np.max(error[0:num_sam,0])))\n",
    "plt.plot(Pred[0:num_sam,0]-Xte_ori[0:num_sam,0].numpy(),'.', c='y')\n",
    "plt.title(str(num_sam)+ \" samples. vs. Target - dx\")\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,0]-Xte_ori[0:num_sam,0].numpy()),np.min(error[0:num_sam,0])),max(np.max(Pred[0:num_sam,0]-Xte_ori[0:num_sam,0].numpy()),np.max(error[0:num_sam,0])))\n",
    "plt.plot(error[0:num_sam,0],'.', c='r')\n",
    "plt.show()\n",
    "\n",
    "plt.title(str(num_sam)+ \" samples. vs. Input - dy\")\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,1]-Xte_ori[0:num_sam,1].numpy()),np.min(error[0:num_sam,1])),max(np.max(Pred[0:num_sam,1]-Xte_ori[0:num_sam,1].numpy()),np.max(error[0:num_sam,1])))\n",
    "plt.plot(Pred[0:num_sam,1]-Xte_ori[0:num_sam,1].numpy(),'.', c='y')\n",
    "plt.title(str(num_sam)+ \" samples. vs. Target - dy\")\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,1]-Xte_ori[0:num_sam,1].numpy()),np.min(error[0:num_sam,1])),max(np.max(Pred[0:num_sam,1]-Xte_ori[0:num_sam,1].numpy()),np.max(error[0:num_sam,1])))\n",
    "plt.plot(error[0:num_sam,1],'.', c='r')\n",
    "plt.show()\n",
    "\n",
    "plt.title(str(num_sam)+ \" samples. vs. Input - dYaw\")\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,2]-Xte_ori[0:num_sam,2].numpy()),np.min(error[0:num_sam,2])),max(np.max(Pred[0:num_sam,2]-Xte_ori[0:num_sam,2].numpy()),np.max(error[0:num_sam,2])))\n",
    "plt.plot(Pred[0:num_sam,2]-Xte_ori[0:num_sam,2].numpy(),'.', c='y')\n",
    "plt.title(str(num_sam)+ \" samples. vs. Target - dYaw\")\n",
    "plt.ylim(min(np.min(Pred[0:num_sam,2]-Xte_ori[0:num_sam,2].numpy()),np.min(error[0:num_sam,2])),max(np.max(Pred[0:num_sam,2]-Xte_ori[0:num_sam,2].numpy()),np.max(error[0:num_sam,2])))\n",
    "plt.plot(error[0:num_sam,2],'.', c='r')\n",
    "plt.show()\n",
    "\n",
    "# plt.title(str(num_sam)+ \" sample - X\")\n",
    "# plt.plot(Yte_LSTM_ori[0,0:num_sam,0],'.', c='r')\n",
    "# plt.plot(Pred[0:num_sam,0],'.', c='c', alpha=0.8)\n",
    "# plt.show()\n",
    "# plt.title(str(num_sam)+ \" sample - Y\")\n",
    "# plt.plot(Yte_LSTM_ori[1,0:num_sam,0],'.', c='r')\n",
    "# plt.plot(Pred[0:num_sam,1],'.', c='c', alpha=0.8)\n",
    "# plt.show()\n",
    " \n",
    "Yte_LSTM_ori=Yte_LSTM_ori.cpu()\n",
    "plt.title(\"Expected - Predicted - X\")\n",
    "plt.scatter(Yte_LSTM_ori[0,:,0], Pred[:,0], s=20.0 , c='r', edgecolors='black')\n",
    "plt.show()\n",
    " \n",
    "plt.title(\"Expected - Predicted - Y\")\n",
    "plt.scatter(Yte_LSTM_ori[1,:,0], Pred[:,1], s=20.0 , c='g', edgecolors='black')\n",
    "plt.show()\n",
    " \n",
    "plt.title(\"Expected - Predicted - YAW\")\n",
    "plt.scatter(Yte_LSTM_ori[2,:,0], Pred[:,2], s=20.0 , c='c', edgecolors='black')\n",
    "plt.show()\n",
    " \n",
    "print(\"TEST error     : \",error_target)\n",
    "print(\"TEST error_in  : \",error_input)\n",
    "print(\"TEST dist      : \", np.sqrt((np.square(Yte_ori[:,0:2].cpu().numpy() - output[:,0:2].cpu().detach().numpy())).mean()))\n",
    "print(\"TEST dist_in   : \", np.sqrt((np.square(Xte_ori[:,0:2].cpu().numpy() - output[:,0:2].cpu().detach().numpy())).mean()))\n",
    "\n",
    "print(\"TEST dyaw      : \", np.sqrt(np.square(error[:,2].mean())))\n",
    "print(\"TEST dyaw_in   : \", np.sqrt((np.square(Xte_ori[:,2].cpu().numpy() - output[:,2].cpu().detach().numpy())).mean()))\n",
    "\n",
    "print(\"TEST dvel      : \", np.sqrt((np.square(Yte_ori[:,3:6].cpu().numpy() - output[:,3:6].cpu().detach().numpy())).mean()))\n",
    "print(\"TEST delv_in   : \", np.sqrt((np.square(Xte_ori[:,3:6].cpu().numpy() - output[:,3:6].cpu().detach().numpy())).mean()))\n",
    "\n",
    "print(\"TEST domg      : \", np.sqrt((np.square(Yte_ori[:,6:8].cpu().numpy() - output[:,6:8].cpu().detach().numpy())).mean()))\n",
    "print(\"TEST domg_in   : \", np.sqrt((np.square(Xte_ori[:,6:8].cpu().numpy() - output[:,6:8].cpu().detach().numpy())).mean()))\n",
    "\n",
    "print('TEST input     : ',Xte_LSTM_ori[0:3,index,:].T.cpu().detach().numpy()[0])\n",
    "print('TEST expected  : ',Yte_LSTM_ori[0:3,index,:].T.cpu().detach().numpy()[0])\n",
    "print('TEST predict   : ',Pred[index,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60234,
     "status": "aborted",
     "timestamp": 1605525509549,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "ONcMg0KK5FMe"
   },
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "plt.title(\"Training - XY\")\n",
    "plt.scatter(Xtr_LSTM_ori[0,:,:], Xtr_LSTM_ori[1,:,:],s=20.0 , c='r', edgecolors='black')\n",
    "plt.show()\n",
    "plt.title(\"Training - X\")\n",
    "plt.plot(Xtr_LSTM_ori[0,:,:],'.', c='c')\n",
    "plt.show()\n",
    "plt.title(\"Training - Y\")\n",
    "plt.plot(Xtr_LSTM_ori[1,:,:],'.', c='c')\n",
    "plt.show()\n",
    "plt.title(\"Training - YAW\")\n",
    "plt.plot(Xtr_LSTM_ori[2,:,:],'.', c='c')\n",
    "plt.show()\n",
    "plt.title(\"Training - V\")\n",
    "plt.scatter(Xtr_LSTM_ori[3,:,:], Xtr_LSTM_ori[4,:,:],s=20.0 , c='y', edgecolors='black')\n",
    "plt.show()\n",
    "plt.title(\"Training - Vx\")\n",
    "plt.plot(Xtr_ori[:,3],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - Vy\")\n",
    "plt.plot(Xtr_ori[:,4],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - Vyaw\")\n",
    "plt.plot(Xtr_ori[:,5],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - wR\")\n",
    "plt.plot(Xtr_ori[:,6],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - wL\")\n",
    "plt.plot(Xtr_ori[:,7],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - tR\")\n",
    "plt.plot(Xtr_ori[:,8],'.', c='g')\n",
    "plt.show()\n",
    "plt.title(\"Training - tL\")\n",
    "plt.plot(Xtr_ori[:,9],'.', c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 60222,
     "status": "aborted",
     "timestamp": 1605525509550,
     "user": {
      "displayName": "Jinhyeok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgEcjZGr9nfbTQ1dLjaTvhrUf9gEpVuk8-H0jSEyQ=s64",
      "userId": "09237695505318520056"
     },
     "user_tz": -540
    },
    "id": "Yla36nCnmgeM",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1987767, 42])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PathNum</th>\n",
       "      <th>NodeNum</th>\n",
       "      <th>baseX</th>\n",
       "      <th>baseY</th>\n",
       "      <th>baseZ</th>\n",
       "      <th>baseR</th>\n",
       "      <th>baseP</th>\n",
       "      <th>baseYaw</th>\n",
       "      <th>base_dX</th>\n",
       "      <th>base_dY</th>\n",
       "      <th>...</th>\n",
       "      <th>F_LHx</th>\n",
       "      <th>F_LHy</th>\n",
       "      <th>F_LHz</th>\n",
       "      <th>F_RHx</th>\n",
       "      <th>F_RHy</th>\n",
       "      <th>F_RHz</th>\n",
       "      <th>LF</th>\n",
       "      <th>RF</th>\n",
       "      <th>LH</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711860</td>\n",
       "      <td>0.607218</td>\n",
       "      <td>42.2079</td>\n",
       "      <td>-0.531854</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>23.14820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.499853</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533830</td>\n",
       "      <td>0.544067</td>\n",
       "      <td>42.6198</td>\n",
       "      <td>-0.427283</td>\n",
       "      <td>-0.181002</td>\n",
       "      <td>23.35030</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.499433</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>-0.008634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.109290</td>\n",
       "      <td>0.393477</td>\n",
       "      <td>43.6022</td>\n",
       "      <td>-0.146997</td>\n",
       "      <td>-0.680728</td>\n",
       "      <td>23.93650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.498777</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>-0.012410</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>-0.015706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602576</td>\n",
       "      <td>0.213741</td>\n",
       "      <td>44.7748</td>\n",
       "      <td>0.272096</td>\n",
       "      <td>-1.427310</td>\n",
       "      <td>24.82910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>-0.024614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178034</td>\n",
       "      <td>0.063151</td>\n",
       "      <td>45.7571</td>\n",
       "      <td>0.793089</td>\n",
       "      <td>-2.355210</td>\n",
       "      <td>25.95050</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987762</th>\n",
       "      <td>15976</td>\n",
       "      <td>77</td>\n",
       "      <td>0.622705</td>\n",
       "      <td>1.090240</td>\n",
       "      <td>0.522588</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>1.334300</td>\n",
       "      <td>0.257720</td>\n",
       "      <td>1.348550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-3.090640</td>\n",
       "      <td>-10.699900</td>\n",
       "      <td>72.49340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987763</th>\n",
       "      <td>15976</td>\n",
       "      <td>78</td>\n",
       "      <td>0.630351</td>\n",
       "      <td>1.131170</td>\n",
       "      <td>0.528825</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.020489</td>\n",
       "      <td>1.361290</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>1.381260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.325180</td>\n",
       "      <td>23.326400</td>\n",
       "      <td>39.87370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987764</th>\n",
       "      <td>15976</td>\n",
       "      <td>79</td>\n",
       "      <td>0.635381</td>\n",
       "      <td>1.159000</td>\n",
       "      <td>0.531467</td>\n",
       "      <td>0.026251</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>1.382130</td>\n",
       "      <td>0.250533</td>\n",
       "      <td>1.401050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.005350</td>\n",
       "      <td>10.391900</td>\n",
       "      <td>12.56110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987765</th>\n",
       "      <td>15976</td>\n",
       "      <td>80</td>\n",
       "      <td>0.637882</td>\n",
       "      <td>1.173050</td>\n",
       "      <td>0.532108</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>1.393550</td>\n",
       "      <td>0.249672</td>\n",
       "      <td>1.409090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.616845</td>\n",
       "      <td>3.168020</td>\n",
       "      <td>3.46435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987766</th>\n",
       "      <td>15976</td>\n",
       "      <td>81</td>\n",
       "      <td>0.645343</td>\n",
       "      <td>1.215600</td>\n",
       "      <td>0.530443</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>1.432270</td>\n",
       "      <td>0.247883</td>\n",
       "      <td>1.425790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987767 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PathNum   NodeNum     baseX     baseY     baseZ     baseR     baseP  \\\n",
       "0              0         1  0.000000  0.000000  0.500000  0.000000 -0.000000   \n",
       "1              0         2  0.000007 -0.000015  0.499853  0.001681  0.000133   \n",
       "2              0         3  0.000031 -0.000074  0.499433  0.006295  0.000469   \n",
       "3              0         4  0.000079 -0.000194  0.498777  0.013196  0.000916   \n",
       "4              0         5  0.000157 -0.000394  0.497918  0.021740  0.001379   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1987762    15976        77  0.622705  1.090240  0.522588  0.011927  0.019628   \n",
       "1987763    15976        78  0.630351  1.131170  0.528825  0.019917  0.020489   \n",
       "1987764    15976        79  0.635381  1.159000  0.531467  0.026251  0.017863   \n",
       "1987765    15976        80  0.637882  1.173050  0.532108  0.029318  0.015757   \n",
       "1987766    15976        81  0.645343  1.215600  0.530443  0.036334  0.007152   \n",
       "\n",
       "          baseYaw   base_dX   base_dY  ...     F_LHx     F_LHy    F_LHz  \\\n",
       "0        0.000000  0.000000  0.000000  ...  1.711860  0.607218  42.2079   \n",
       "1       -0.001566  0.001424 -0.003399  ...  1.533830  0.544067  42.6198   \n",
       "2       -0.005890  0.003489 -0.008634  ...  1.109290  0.393477  43.6022   \n",
       "3       -0.012410  0.006194 -0.015706  ...  0.602576  0.213741  44.7748   \n",
       "4       -0.020566  0.009539 -0.024614  ...  0.178034  0.063151  45.7571   \n",
       "...           ...       ...       ...  ...       ...       ...      ...   \n",
       "1987762  1.334300  0.257720  1.348550  ...  0.000000  0.000000   0.0000   \n",
       "1987763  1.361290  0.252653  1.381260  ...  0.000000  0.000000   0.0000   \n",
       "1987764  1.382130  0.250533  1.401050  ...  0.000000  0.000000   0.0000   \n",
       "1987765  1.393550  0.249672  1.409090  ...  0.000000  0.000000   0.0000   \n",
       "1987766  1.432270  0.247883  1.425790  ...  0.000000  0.000000   0.0000   \n",
       "\n",
       "            F_RHx      F_RHy     F_RHz   LF  RF  LH  RH  \n",
       "0       -0.531854   0.006337  23.14820    1   1   1   1  \n",
       "1       -0.427283  -0.181002  23.35030    1   1   1   1  \n",
       "2       -0.146997  -0.680728  23.93650    1   1   1   1  \n",
       "3        0.272096  -1.427310  24.82910    1   1   1   1  \n",
       "4        0.793089  -2.355210  25.95050    1   1   1   1  \n",
       "...           ...        ...       ...  ...  ..  ..  ..  \n",
       "1987762 -3.090640 -10.699900  72.49340    1   0   0   1  \n",
       "1987763  4.325180  23.326400  39.87370    1   0   0   1  \n",
       "1987764  2.005350  10.391900  12.56110    1   0   0   1  \n",
       "1987765  0.616845   3.168020   3.46435    1   0   0   1  \n",
       "1987766  0.000000   0.000000   0.00000    0   0   0   0  \n",
       "\n",
       "[1987767 rows x 42 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../../data/csv/Hound_data.txt')\n",
    "\n",
    "Quad_data = torch.tensor(data.values)\n",
    "# Quad_data = Quad_data[:-1,:]\n",
    "print(np.shape(Quad_data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1987686/1987767 [02:03<00:00, 16071.52it/s]\n"
     ]
    }
   ],
   "source": [
    "path=[0]*data.PathNum.max()\n",
    "path_idx=-1\n",
    "\n",
    "for idx in tqdm(range(len(Quad_data)), position=0, leave=True):\n",
    "  if path_idx+1 == Quad_data[idx,0]:\n",
    "    # Increase path index\n",
    "    tmp=[]\n",
    "    path_idx = path_idx+1\n",
    "    if path_idx == data.PathNum.max():\n",
    "      # Skip last path\n",
    "      break;\n",
    "  if Quad_data[idx,0]==path_idx:\n",
    "    # Rearrange data into (path, samples, variables)\n",
    "    tmp.append(Quad_data[idx,2:].tolist())\n",
    "    path[path_idx]=tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPuT03Y2SsjS34+0aW8HDd3",
   "collapsed_sections": [],
   "mount_file_id": "1ako2vT-VmK0a73N6hA1W-BQYKglub1iv",
   "name": "PI_LSTMsNN_Quadruped.ipynb",
   "provenance": [
    {
     "file_id": "1GlrcdI8P7jeZqVkuUSfyE0pIBF1juS3y",
     "timestamp": 1605249608485
    },
    {
     "file_id": "1Gvb7XV3Jv7GhGNbJMye23DRdu5ubPxki",
     "timestamp": 1605181890521
    },
    {
     "file_id": "1W24XkYocc5hOTmsQFxJoC-yh7T_GjnBh",
     "timestamp": 1597804915213
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
